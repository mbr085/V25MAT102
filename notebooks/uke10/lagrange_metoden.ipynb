{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de92d64-8069-44e5-b811-866eb5b36dec",
   "metadata": {},
   "source": [
    "# Lagrange multiplikator metoden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035118d-4286-498c-9234-769e5a9142b1",
   "metadata": {},
   "source": [
    "Vi ser nå på to funksjoner $f, g \\colon \\mathbb{R}^n \\to \\mathbb{R}$.\n",
    "Problemet vi stiller oss er å finne et minmum for $f$ på mengden\n",
    "$M = \\{ \\mathbf{x}\\in \\mathbb{R}^n \\mid\n",
    "g(\\mathbf{x}) = 0 \\}$. Vi antar at $f$ og $g$ er differensierbare og at\n",
    "$\\nabla g(\\mathbf{x})\n",
    "\\ne 0$ for alle $\\mathbf{x}\\in M$.\n",
    "\n",
    "I situasjonen over sier vi også at vi søker et minimum for $f$ under\n",
    "betingelsen $g(x) = 0$.\n",
    "\n",
    "Vi følger nøye strategien fra gradient descent: La\n",
    "$\\mathbf{y}\\colon \\mathbb{R}\\to \\mathbb{R}^n$ være en løsning til\n",
    "differensialligningen\n",
    "$$\\mathbf{y}'(t) = - \\nabla f(\\mathbf{y}(t)) + \\lambda(t) \\nabla g(\\mathbf{y}(t))$$\n",
    "der $\\lambda \\colon \\mathbb{R}\\to \\mathbb{R}$ er funksjonen\n",
    "$$\\lambda(t) = \\frac{\\nabla f(\\mathbf{y}(t)) \\cdot \\nabla g(\\mathbf{y}(t))}{\\nabla g(\\mathbf{y}(t)) \\cdot \\nabla g(\\mathbf{y}(t))}.$$\n",
    "\n",
    "Fra kjerneregelen har vi at\n",
    "$(g \\circ y)'(t) = \\nabla g(\\mathbf{y}(t)) \\cdot \\mathbf{y}'(t).$\n",
    "\n",
    "**Oppgave 1**. Vis at $(g \\circ y)'(t) = 0$ for alle $t$.\n",
    "\n",
    "Siden\n",
    "$|\\nabla f(\\mathbf{y}(t)) \\cdot \\nabla g(\\mathbf{y}(t)) \\le |\\nabla f(\\mathbf{y}(t)| |\\nabla g(\\mathbf{y}(t))||$,\n",
    "ser vi at\n",
    "\n",
    "$$\\begin{aligned}\n",
    "  (f \\circ g)'(t)\n",
    "  &= \\nabla f(\\mathbf{y}(t)) \\cdot \\mathbf{y}'(t)\\\\\n",
    "  &= -|\\nabla f(\\mathbf{y}(t)|^2 +\n",
    "  \\frac{(\\nabla f(\\mathbf{y}(t)) \\cdot \\nabla g(\\mathbf{y}(t)))^2}\n",
    "  {(\\nabla g(\\mathbf{y}(t)) \\cdot \\nabla g(\\mathbf{y}(t)))}\n",
    "  \\le\\\\\n",
    "  &= -|\\nabla f(\\mathbf{y}(t)|^2 +\n",
    "  \\frac{|\\nabla f(\\mathbf{y}(t))|^2 |\\nabla g(\\mathbf{y}(t))|^2}\n",
    "  {|\\nabla g(\\mathbf{y}(t))|^2} = 0.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Som for gradient descent ser vi at dersom $\\mathbf{y}(t)$ går mot et\n",
    "punkt $\\mathbf{p}$ for $t \\to \\infty$, da er\n",
    "$(f \\circ \\mathbf{y})'(t) \\to 0$ for $t \\to \\infty$. Siden\n",
    "$(f \\circ \\mathbf{y})'(t) = -| \\nabla f(\\mathbf{y}(t))|^2 + \\lambda(t)\\nabla f(\\mathbf{y}(t)) \\cdot \\nabla\n",
    "g(\\mathbf{y}(t))$ for alle $t$, ser vi at\n",
    "$-| \\nabla f(\\mathbf{p})|^2 + \\lambda(t)\\nabla f(\\mathbf{p}) \\cdot \\nabla g(\\mathbf{p}) =0$.\n",
    "Setter si inn for $\\lambda(t)$ og setter vi\n",
    "$\\widetilde \\lambda = \\lim_{t \\infty} \\lambda(t)$ får vi at dette bare\n",
    "er mulig dersom\n",
    "$\\nabla f(\\mathbf{p}) = \\widetilde \\lambda \\nabla g(\\mathbf{p})$.\n",
    "\n",
    "Omvendt, hvis $\\mathbf{p}$ er et minimum for $f$ under betingelsen\n",
    "$g(\\mathbf{x}) = 0$, da er\n",
    "$\\nabla f(\\mathbf{p}) = \\widetilde \\lambda \\nabla g(\\mathbf{p})$ for en\n",
    "$\\widetilde \\lambda$ fordi den konstante funksjonen\n",
    "$\\mathbf{y}(t) = \\mathbf{p}$ er en løsning til differensialligningen\n",
    "over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082019be-c4d4-4543-838a-bb8f5e67189a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
